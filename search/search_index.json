{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>Welcome to QScaler!</p> <p>QScaler is an open-source, Kubernetes-native worker controller designed to optimize the management of queue-based workloads. It dynamically scales pods based on queue activity, such as rate and length, offering a smarter alternative to existing solutions like KEDA. By focusing on seamless scaling and preserving in-progress tasks, QScaler ensures efficient and reliable processing in distributed systems.</p>"},{"location":"CONTRIBUTING/","title":"Developers","text":""},{"location":"CONTRIBUTING/#how-to-contribute","title":"How To Contribute","text":"<p>We appreciate contributions from the community to make QScaler even better. To contribute, follow the steps below:</p> <ol> <li>Fork the QScaler repository to your GitHub account.</li> <li>Clone the forked repository to your local machine: <pre><code>git clone https://github.com/your-username/QScaler.git\n</code></pre></li> <li>Create a new branch to work on your feature or bug fix: <pre><code>git checkout -b my-feature\n</code></pre></li> <li>Make your changes, following the coding guidelines outlined in this document.</li> <li>Commit your changes with clear and descriptive commit messages and sign it: <pre><code>git commit -s -m \"fix: Add new feature\"\n</code></pre></li> <li>please make sure you commit as described in conventional commit</li> <li>Push your changes to your forked repository: <pre><code>git push origin my-feature\n</code></pre></li> <li>Open a pull request against the main branch of the original QScaler repository.</li> </ol>"},{"location":"CONTRIBUTING/#pull-requests","title":"Pull Requests","text":"<p>We welcome and appreciate contributions from the community. If you have developed a new feature, improvement, or bug fix for QScaler, follow these steps to submit a pull request:</p> <ol> <li>Make sure you have forked the QScaler repository and created a new branch for your changes. Checkout How To Contribute.</li> <li>commit your changes and push them to your forked repository.</li> <li>Go to the QScaler repository on GitHub.</li> <li>Click on the \"New Pull Request\" button.</li> <li>Select your branch and provide a descriptive title and detailed description of your changes.</li> <li>If your pull request relates to an open issue, reference the issue in the description using the GitHub issue syntax (e.g., Fixes #123).</li> <li>Submit the pull request, and our team will review your changes. We appreciate your patience during the review process and may provide feedback or request further modifications.</li> </ol>"},{"location":"CONTRIBUTING/#pull-request-naming","title":"Pull Request Naming","text":"<p>The name should follow conventional commit naming. </p>"},{"location":"CONTRIBUTING/#coding-guidelines","title":"Coding Guidelines","text":"<p>To maintain a consistent codebase and ensure readability, we follow a set of coding guidelines in QScaler. Please adhere to the following guidelines when making changes:</p> <ul> <li>Follow the Effective Go guide for Go code.</li> <li>Follow the Folder convention guide for Go code.</li> <li>Write clear and concise comments to explain the code's functionality.</li> <li>Use meaningful variable and function names.</li> <li>Make sure your code is properly formatted and free of syntax errors.</li> <li>Run tests locally.</li> <li>Check that the feature documented.</li> <li>Add new packages only if necessary and already existing one, can't be used.</li> <li>Add tests for new features or modification.</li> </ul>"},{"location":"CONTRIBUTING/#local-deployment","title":"Local deployment","text":"<p>To make it easy to develop locally, please run the following</p> <p>Prerequisites : 1. install helm <pre><code>brew install helm\n</code></pre> 2. install kubectl <pre><code>brew install kubectl\n</code></pre> 3. install docker</p> <ol> <li>install kind <pre><code>brew install kind\n</code></pre></li> </ol> <p>Deployment: 1. make sure docker are running.  2. use <code>make deploy</code>. it will do the following:      * deploy a local registry as container      * deploy a kind cluster as container with configuration      * deploy QScaler with the local helm chart</p>"},{"location":"concepts/qworker/","title":"QWorker CRD","text":"<p>The <code>QWorker</code> Custom Resource Definition (CRD) is designed to define and manage worker pods that process tasks from a message queue. It integrates with the <code>ScalerConfig</code> resource to enable dynamic scaling and efficient resource utilization.</p>"},{"location":"concepts/qworker/#schema","title":"Schema","text":"<p>The <code>QWorker</code> CRD consists of two main sections: <code>spec</code> and <code>status</code>.</p>"},{"location":"concepts/qworker/#fields","title":"Fields","text":""},{"location":"concepts/qworker/#spec","title":"Spec","text":"<ul> <li><code>podSpec</code>: Defines the pod template for the worker, using Kubernetes <code>PodSpec</code>.</li> <li><code>scaleConfig</code>: Contains configuration details for scaling.<ul> <li><code>scalerConfigRef</code>: Reference to a <code>ScalerConfig</code> resource.</li> <li><code>queue</code>: The name of the message queue to process.</li> <li><code>minReplicas</code>: Minimum number of worker replicas.</li> <li><code>maxReplicas</code>: Maximum number of worker replicas.</li> <li><code>scalingFactor</code>: Controls the scaling sensitivity.</li> <li><code>activateVPA</code>: Boolean to enable or disable Vertical Pod Autoscaler (VPA) for dynamic resource allocation.</li> </ul> </li> </ul>"},{"location":"concepts/qworker/#status","title":"Status","text":"<ul> <li><code>currentReplicas</code>: The current number of worker replicas.</li> <li><code>desiredReplicas</code>: The desired number of worker replicas based on queue metrics.</li> <li><code>currentPodSpecHash</code>: Hash of the current <code>podSpec</code> for consistency checks.</li> <li><code>maxContainerResourcesUsage</code>: Tracks maximum resource usage per container in the worker pods.</li> </ul>"},{"location":"concepts/qworker/#example-qworker-resource","title":"Example: <code>QWorker</code> Resource","text":"<p>Here is an example definition of a <code>QWorker</code> resource:</p> <pre><code>apiVersion: quickube.com/v1alpha1\nkind: QWorker\nmetadata:\n  name: example-qworker\nspec:\n  podSpec:\n    containers:\n      - name: worker\n        image: worker-image:latest\n        resources:\n          requests:\n            cpu: \"500m\"\n            memory: \"256Mi\"\n  scaleConfig:\n    scalerConfigRef: \"example-scaler-config\"\n    queue: \"task-queue\"\n    minReplicas: 1\n    maxReplicas: 10\n    scalingFactor: 2\n    activateVPA: true\n</code></pre>"},{"location":"concepts/qworker/#rollouts","title":"Rollouts","text":"<p>QScaler leverages <code>status.currentPodSpecHash</code> to manage worker rollouts. Each worker completes its current task, and if its hash does not match the CRD, it terminates itself to align with the updated specification.</p>"},{"location":"concepts/qworker/#horizontal-pod-autoscaling-hpa","title":"Horizontal Pod Autoscaling (HPA)","text":"<p>Currently, only HPA is supported based on queue length. QScaler scales the number of worker pods based on the number of messages in the queue, using the value specified in <code>spec.scaleConfig.scalingFactor</code>.</p> <p>Additionally, worker pods terminate themselves if the <code>status.currentPodSpecHash</code> changes or if <code>status.desiredReplicas</code> is less than <code>status.currentReplicas</code>.</p>"},{"location":"concepts/qworker/#vertical-pod-autoscaling-vpa","title":"Vertical Pod Autoscaling (VPA)","text":"<p>To enable VPA, ensure the Kubernetes metrics server is installed in the cluster. Use the following command to install it:</p> <pre><code>curl -sSL https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml \\\n    | yq '.spec.template.spec.containers[0].args += \"--kubelet-insecure-tls\"' - \\\n    | kubectl apply -f -\n</code></pre> <p>When VPA is activated by setting <code>spec.scaleConfig.activateVPA=true</code>, the controller tracks the maximum actual resource usage and writes this information to the CRD's <code>status</code> field.</p>"},{"location":"concepts/scalerconfig/","title":"ScalerConfig CRD","text":"<p>The <code>ScalerConfig</code> Custom Resource Definition (CRD) is utilized by the <code>ScalerConfig</code> controller and provisioned workers to authenticate with a message broker system.</p>"},{"location":"concepts/scalerconfig/#schema","title":"Schema","text":"<p>The schema leverages the <code>type</code> and <code>config</code> fields to dynamically select the appropriate configuration for each supported broker. Currently, only Redis is supported.</p>"},{"location":"concepts/scalerconfig/#fields","title":"Fields","text":"<ul> <li><code>type</code>: Specifies the type of scaler configuration (e.g., <code>redis</code>).</li> <li><code>config</code>: Contains configuration details specific to the chosen scaler type.</li> </ul>"},{"location":"concepts/scalerconfig/#redis-configuration","title":"Redis Configuration","text":"<ul> <li><code>host</code>: The hostname or IP address of the Redis instance.</li> <li><code>port</code>: The port number of the Redis instance.</li> <li><code>password</code>: The Redis password, which can be provided as plaintext or through a Kubernetes secret.</li> </ul>"},{"location":"concepts/scalerconfig/#example-scalerconfig-resource","title":"Example: <code>ScalerConfig</code> Resource","text":"<p>Here is an example definition of a <code>ScalerConfig</code> resource:</p> <pre><code>apiVersion: quickube.com/v1alpha1\nkind: ScalerConfig\nmetadata:\n  name: example-scaler-config\nspec:\n  type: \"redis\"\n  config:\n    host: \"redis-host\"\n    port: \"6379\"\n    password:\n      value: \"your-password\"\n      # Alternatively, use a secret:\n      # secret:\n      #   name: \"redis-secret\"\n      #   key: \"password\"\n</code></pre>"},{"location":"getting_started/installation/","title":"Installation","text":""},{"location":"getting_started/installation/#installation","title":"Installation","text":"<p>To add piper helm repo run:</p> <pre><code>helm repo add piper https://qscaler.quickube.com\n</code></pre> <p>After configuring Piper values.yaml, run the following command for installation:</p> <pre><code>helm upgrade --install qscaler quickube/qscaler \\\n-f YOUR_VALUES_FILE.yaml\n</code></pre>"},{"location":"getting_started/setup/","title":"Setup Broker","text":""},{"location":"getting_started/setup/#setup","title":"Setup","text":"<p>QScaler scales using broker message as a queue and monitors it. To use it, deploy a message broker in K8s.</p>"},{"location":"getting_started/setup/#redis","title":"Redis","text":"<p>To use redis with in memory storage as the queue message broker install it with:</p> <pre><code>helm upgrade -n YOUR_NAMESPACE --install redis oci://registry-1.docker.io/bitnamicharts/redis \\\n  --set global.redis.password=YOUR_PASSWORD_HERE \\\n  --set architecture=standalone \\\n  --set persistence=false\n</code></pre> <p>Then create a QScaler crd that will be consumed by the controller and workers:</p> <pre><code>apiVersion: quickube.com/v1alpha1\nkind: ScalerConfig\nmetadata:\n  name: redis-config\n  namespace: YOUR_NAMESPACE\nspec:\n  type: redis\n  config:\n    host: redis-master.YOUR_NAMESPACE.svc.cluster.local\n    port: \"6379\"\n    password:\n      secret:\n        name: redis\n        key: redis-password\n</code></pre>"},{"location":"usage/python_example/","title":"Python SDK Example for QWorker","text":"<p>This guide demonstrates how to use the <code>qscaler_sdk</code> Python library to create and deploy a worker that processes tasks from a queue. The worker integrates seamlessly with QScaler to support dynamic scaling and resource optimization.</p>"},{"location":"usage/python_example/#example-code","title":"Example Code","text":"<p>Here is an example Python worker implementation using the <code>qscaler_sdk</code>:</p> <pre><code>import logging\nimport time\nfrom typing import Dict, Any\n\nfrom qscaler_sdk.worker import Worker\n\nworker = Worker()\n\n@worker.shutdown\ndef shutdown():\n    print(\"Shutting down worker...\")\n\n@worker.task\ndef example(task: Dict[str, Any]) -&gt; Any:\n    print(\"hello this is an example\")\n    time.sleep(5)\n\nif __name__ == \"__main__\":\n    logging.basicConfig()\n    worker.k8s_client.extract_secret_value(\"redis\", \"redis-password\")\n    worker.run()\n</code></pre>"},{"location":"usage/python_example/#explanation","title":"Explanation","text":"<ol> <li> <p>Initialization:</p> <ul> <li>A <code>Worker</code> instance is created to manage tasks and integration with QScaler.</li> </ul> </li> <li> <p>Task Definition:</p> <ul> <li>The <code>@worker.task</code> decorator defines a task function. This function processes individual tasks pulled from the queue.</li> </ul> </li> <li> <p>Shutdown Hook:</p> <ul> <li>The <code>@worker.shutdown</code> decorator defines a cleanup function to be executed during shutdown.</li> </ul> </li> <li> <p>Run the Worker:</p> <ul> <li>The <code>worker.run()</code> method starts the worker loop, which continuously pulls and processes tasks.</li> </ul> </li> <li> <p>Kubernetes Integration:</p> <ul> <li>The <code>worker.k8s_client.extract_secret_value</code> method retrieves secrets, such as the Redis password, from Kubernetes.</li> </ul> </li> </ol>"},{"location":"usage/python_example/#example-qworker-resource","title":"Example QWorker Resource","text":"<p>Below is the YAML configuration for deploying the worker in Kubernetes:</p> <pre><code>apiVersion: quickube.com/v1alpha1\nkind: QWorker\nmetadata:\n  labels:\n    app.kubernetes.io/name: qworker\n  name: qworker-example\nspec:\n  podSpec:\n    serviceAccountName: qscaler-worker\n    containers:\n      - name: pyworker\n        image: localhost:5001/worker:latest\n        imagePullPolicy: Always\n  scaleConfig:\n    activateVPA: true\n    queue: \"queue1\"\n    minReplicas: 1\n    maxReplicas: 5\n    scalerConfigRef: redis-config\n    scalingFactor: 1\n</code></pre>"},{"location":"usage/python_example/#key-points","title":"Key Points","text":"<ul> <li> <p><code>podSpec</code>:</p> <ul> <li>Defines the container image and resource requirements for the worker pod.</li> </ul> </li> <li> <p><code>scaleConfig</code>:</p> <ul> <li>Configures scaling parameters, such as the queue to monitor, minimum and maximum replicas, and scaling factor.</li> </ul> </li> </ul>"},{"location":"usage/python_example/#dockerfile-for-worker","title":"Dockerfile for Worker","text":"<p>Here is the <code>Dockerfile</code> to containerize the Python worker:</p> <pre><code>FROM python:3.11-alpine\n\nWORKDIR /app\n\nRUN pip install poetry\n\nCOPY . .\n\nRUN poetry env use python\nRUN poetry install\n\nCOPY ./examples/worker.py ./worker.py\n\nCMD [\"poetry\", \"run\", \"python3\", \"/app/worker.py\"]\n</code></pre>"},{"location":"usage/python_example/#build-and-push-image","title":"Build and Push Image","text":"<ol> <li> <p>Build the Docker image:    <pre><code>docker build -t localhost:5001/worker:latest .\n</code></pre></p> </li> <li> <p>Push the image to your local registry:    <pre><code>docker push localhost:5001/worker:latest\n</code></pre></p> </li> </ol>"},{"location":"usage/python_example/#deploying-the-worker","title":"Deploying the Worker","text":"<ol> <li> <p>Apply the <code>QWorker</code> resource to your Kubernetes cluster:    <pre><code>kubectl apply -f qworker-example.yaml\n</code></pre></p> </li> <li> <p>Verify the deployment:    ```bash    kubectl get pods -l app.kubernetes.io/name=qworker</p> </li> </ol>"}]}